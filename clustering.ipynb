{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6815c-c7bf-43cb-aee9-c8ecc459cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q 1:   What is the difference between K-Means and Hierarchical Clustering? Provide a use case for each.\n",
    "\n",
    "    :-K-Means clustering is a partition-based algorithm that divides data into a predefined\n",
    "      number of clusters (K) by minimizing intra-cluster variance. It is fast and efficient\n",
    "      for large datasets but requires the number of clusters in advance.\n",
    "      Hierarchical clustering builds a tree-like structure (dendrogram) of clusters without\n",
    "      requiring a predefined number of clusters. It can be agglomerative (bottom-up) or divisive\n",
    "     (top-down) and is useful for understanding cluster relationships.\n",
    "      Use cases:\n",
    "      K-Means: Customer segmentation in large e-commerce datasets\n",
    "      Hierarchical: Gene expression analysis or document clustering\n",
    "\n",
    "#Q 2: Explain the purpose of the Silhouette Score in evaluating clustering algorithms. \n",
    " \n",
    ":-    The Silhouette Score measures how well a data point fits within\n",
    "      its assigned cluster compared to other clusters.\n",
    "      Its value ranges from –1 to +1:\n",
    "      +1 → well clustered\n",
    "       0 → overlapping clusters\n",
    "       –1 → incorrect clustering\n",
    "       It helps in evaluating clustering quality and selecting the optimal number of clusters.\n",
    "\n",
    "#Q 3:What are the core parameters of DBSCAN, and how do they influence the clustering process? \n",
    " \n",
    ":-   The two core parameters of DBSCAN are:\n",
    "     eps (ε): Maximum distance between two points to be considered neighbors\n",
    "     min_samples: Minimum number of points required to form a dense region\n",
    "     Influence:\n",
    "     Small eps → many points marked as noise\n",
    "     Large eps → clusters may merge\n",
    "     Higher min_samples → stricter cluster formation\n",
    "\n",
    "#Q 4:Why is feature scaling important when applying clustering algorithms like K-Means and DBSCAN?\n",
    "\n",
    ":-    Feature scaling is important because clustering algorithms like K-Means and DBSCAN use distance calculations.\n",
    "      If features are on different scales, larger-scale features dominate the distance, leading to incorrect clustering.\n",
    "      Standardization ensures equal contribution of all features.\n",
    "\n",
    "#Q 5: What is the Elbow Method in K-Means clustering and how does it help determine the optimal number of clusters?\n",
    "    \n",
    ":-     The Elbow Method is used to determine the optimal number of clusters (K) by plotting K against\n",
    "       the Within-Cluster Sum of Squares (WCSS).\n",
    "       As K increases, WCSS decreases.\n",
    "      The point where the decrease slows down significantly (forming an “elbow”) is considered the optimal K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4aa147-25a4-43af-8ddb-41b51a53bab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_blobs\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#Question 6: Generate synthetic data using make_blobs(n_samples=300, centers=4), apply KMeans clustering, and visualize the results with cluster centers. (Include your Python code and output in the code box below.) \n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, _ = make_blobs(n_samples=300, centers=4, random_state=42)\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=labels)\n",
    "plt.scatter(centers[:,0], centers[:,1], marker='X', s=200)\n",
    "plt.title(\"K-Means Clustering with Cluster Centers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b92f960-07a2-469d-837e-33311df8537c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_wine\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DBSCAN\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#Q7 : Load the Wine dataset, apply StandardScaler , and then train a DBSCAN model. Print the number of clusters found (excluding noise).\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "wine = load_wine()\n",
    "X = StandardScaler().fit_transform(wine.data)\n",
    "\n",
    "db = DBSCAN(eps=1.5, min_samples=5)\n",
    "labels = db.fit_predict(X)\n",
    "\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(\"Number of clusters:\", n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a8c757-e224-45a8-9f6f-5df793c1f7a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_moons\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DBSCAN\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#Q8 Generate moon-shaped synthetic data using make_moons(n_samples=200, noise=0.1), apply DBSCAN, and highlight the outliers in the plot\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, _ = make_moons(n_samples=200, noise=0.1, random_state=42)\n",
    "\n",
    "db = DBSCAN(eps=0.3, min_samples=5)\n",
    "labels = db.fit_predict(X)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=labels)\n",
    "plt.title(\"DBSCAN on Moon-Shaped Data (Outliers Highlighted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6613283e-3f2e-4bc9-a33c-906c10f12b02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_wine\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#Q9: Load the Wine dataset, reduce it to 2D using PCA, then apply Agglomerative Clustering and visualize the result in 2D with a scatter plot.\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wine = load_wine()\n",
    "X = StandardScaler().fit_transform(wine.data)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "labels = agg.fit_predict(X_pca)\n",
    "\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels)\n",
    "plt.title(\"Agglomerative Clustering after PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd7fd95-ef8c-4641-b1db-d0084d00b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#​Q 10: 10: You are working as a data analyst at an e-commerce company. The marketing team wants to segment customers based on their purchasing behavior to run targeted promotions.\n",
    "#           The dataset contains customer demographics and their product purchase history across categories. Describe your real-world data science workflow using clustering:\n",
    "#           Which clustering algorithm(s) would you use and why? ● How would you preprocess the data (missing values, scaling)? ● How would you determine the number of clusters? \n",
    "#           How would the marketing team benefit from your clustering analysis? \n",
    "\n",
    ":-    ​Algorithm: I would use K-Means for its efficiency and ease of interpretation, or DBSCAN \n",
    "       if I suspect there are irregularly shaped clusters or many outliers (one-time buyers).\n",
    "      ​Preprocessing: * Missing Values: Use median imputation for numerical data (like age) or a \"Missing\" category for categorical data. \n",
    "      ​Scaling: Use StandardScaler because purchase history amounts and demographics have wildly different scales .\n",
    "      ​Determining Clusters: Use the Elbow Method combined with the Silhouette Score to ensure clusters are distinct and meaningful.\n",
    "      ​Marketing Benefit: * Personalization: Send high-end luxury offers to the \"High Spender\" cluster. \n",
    "      ​Retention: Send discount codes to the \"Churn-risk\" cluster (infrequent buyers).\n",
    "      ​Efficiency: Save budget by not sending generic ads to groups unlikely to respond"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
